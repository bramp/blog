<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hack on bramp.net</title>
    <link>http://bramp.net/blog/tags/hack/</link>
    <description>Recent content in Hack on bramp.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Tue, 27 Nov 2012 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://bramp.net/blog/tags/hack/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Invalid IP range checking defeated by DNS</title>
      <link>http://bramp.net/blog/2012/11/27/invalid-ip-range-checking-defeated-by-dns/</link>
      <pubDate>Tue, 27 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>http://bramp.net/blog/2012/11/27/invalid-ip-range-checking-defeated-by-dns/</guid>
      <description>&lt;p&gt;I&amp;#8217;ve seen a particular kind of vulnerability in a few different applications but I&amp;#8217;m not sure of an appropriate name for it. So I thought I&amp;#8217;d write about it, and informally call it the &amp;#8220;DNS defeated IP address check&amp;#8221;. Basically, if you have an application that can be used as a proxy, or can be instructed to make web request, you don&amp;#8217;t want it fetching files from internal services.&lt;/p&gt;

&lt;p&gt;For example, there is a simple proxy called &lt;a href=&#34;https://github.com/atmos/camo&#34;&gt;Camo&lt;/a&gt;, which is used to fetch third party images when you need to display them on a SSL secure site. (Read more about Camo on the &lt;a href=&#34;https://github.com/blog/743-sidejack-prevention-phase-3-ssl-proxied-assets&#34;&gt;GitHub blog&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;This kind of application can be incorrectly setup such that the application has access to internal servers and resources that wouldn&amp;#8217;t normally be exposed to the Internet. This make the proxy application a good way a hacker could gain information about a private network. However Camo tries to address this issue by forbidding URLs that contain private IP addresses. It does a check like so:&lt;/p&gt;

&lt;pre&gt;RESTRICTED_IPS = /^((10\.)|(127\.)|(169\.254)|(192\.168)|(172\.((1[6-9])|(2[0-9])|(3[0-1]))))/

if (url.host.match(RESTRICTED_IPS))
  return four_oh_four(resp, &#34;Hitting excluded hostnames&#34;)
&lt;/pre&gt;

&lt;p&gt;This code (written for &lt;a href=&#34;http://nodejs.org/&#34;&gt;Node.js&lt;/a&gt; in &lt;a href=&#34;http://coffeescript.org/&#34;&gt;CoffeeScript&lt;/a&gt;) is taking a &lt;a href=&#34;http://nodejs.org/api/url.html&#34;&gt;url object&lt;/a&gt; and checking the hostname doesn&amp;#8217;t match a restricted address. This works great against URLs such as &lt;a href=&#34;http://127.0.0.1/&#34;&gt;http://127.0.0.1/&lt;/a&gt;, or &lt;a href=&#34;http://10.0.0.1/&#34;&gt;http://10.0.0.1/&lt;/a&gt;, however this check can easily be defeated. If you create a domain name, such as localhost.bramp.net, which resolves to 127.0.0.1, and ask the proxy to fetch &lt;a href=&#34;http://localhost.bramp.net/&#34;&gt;http://localhost.bramp.net/&lt;/a&gt;, then it won&amp;#8217;t be caught by that check. Now the proxy will continue to try and fetch a resource from 127.0.0.1.&lt;/p&gt;

&lt;p&gt;The solution to this problem is to do that IP address check &lt;strong&gt;after&lt;/strong&gt; the DNS name has been resolved. This can also be problematic if you use a standard library for making web requests, as they will do the DNS lookup for you, and don&amp;#8217;t give you the fine grain control you need. For example, I&amp;#8217;ve seen this be a problem for a Java application using the &lt;a href=&#34;http://hc.apache.org/httpclient-3.x/&#34;&gt;Apache HTTP Client&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One might naively assume they could do a DNS check, and then hand the processing to a HTTP library to make the actual request. The issue here is that the DNS record the HTTP library uses might not be the same as the one you checked against with the DNS check. For example, many domains have multiple A records, and some DNS servers can be configured to round robin DNS records. If you can&amp;#8217;t be sure the HTTP library will do another DNS requests, then you&amp;#8217;d be vulnerable.&lt;/p&gt;

&lt;p&gt;Luckily, in Camo&amp;#8217;s case the fix was relatively easy (see my &lt;a href=&#34;https://github.com/atmos/camo/pull/19&#34;&gt;pull request&lt;/a&gt;).&lt;/p&gt;

&lt;pre&gt;# We do DNS lookup ourselves
Dns.lookup url.host, (err, address, family) -&gt;
  if address.match(RESTRICTED_IPS)
    return four_oh_four(resp, &#34;Hitting excluded hostnames&#34;)

  # We connect to the IP address, not hostname
  src = Http.createClient url.port || 80, address

  # We add a host header, so the request will work
  headers = 
    &#34;Host&#39; : url.host

  # Boom, we make the request
  srcReq = src.request &#39;GET&#39;, query_path, headers
&lt;/pre&gt;

&lt;p&gt;The above code was simplified a little from the real code, but basically we do the DNS lookup, check the returned address is good, and then make a HTTP request to that IP address with a &lt;code&gt;Host:&lt;/code&gt; header to ensure the request will work.&lt;/p&gt;

&lt;p&gt;Really though, the correct solution to this is to configure a suitably paranoid firewall to stop requests from the proxy machine to anything internal. However, as with all security, the more [layers of protection][8] you have the better, and you should never depend on just one.&lt;/p&gt;

&lt;p&gt;[8]: &lt;a href=&#34;http://en.wikipedia.org/wiki/Swiss_cheese_model&#34;&gt;http://en.wikipedia.org/wiki/Swiss_cheese_model&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PHP Destructor objects</title>
      <link>http://bramp.net/blog/2011/11/02/php-destructor-objects/</link>
      <pubDate>Wed, 02 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>http://bramp.net/blog/2011/11/02/php-destructor-objects/</guid>
      <description>&lt;p&gt;PHP&amp;#8217;s lack of a finally keyword is apalling, and even though there seems to be some hacks around it, I have come up with own today. I&amp;#8217;m following the C++ concept of allocating objects on the stack, and letting them cleanup any resources when the stack is rolled back.&lt;/p&gt;

&lt;p&gt;Take an example. I am creating some files that I want to always be deleted after the script has finished. In any sane language (that has Exceptions) I would write:&lt;/p&gt;

&lt;pre class=&#34;prettyprint&#34;&gt;try {
  // Create files
  // Do something with the files
} finally {
  // Delete files - This code will run no matter what exceptions or errors occur while creating the files.
}
&lt;/pre&gt;

&lt;p&gt;However, this is the hack I&amp;#8217;ve managed with PHP:&lt;/p&gt;

&lt;pre class=&#34;prettyprint&#34;&gt;class UnlinkMe {
    var $filename;

    function __construct($filename) {
        $this-&amp;gt;filename = $filename;
    }

    function __destruct() {
        unlink($this-&amp;gt;filename);
    }
}

// To use:
function doSomething() {
  $unlinkme = new UnlinkMe(&#39;/tmp/filename&#39;):

  // Do some work with the files

  return;
}
&lt;/pre&gt;

&lt;p&gt;Here we are creating a UnlinkMe object, that has a destructor set up to delete a file. This UnlinkMe object is only used in the doSomething() function. Once that function returns, there are no longer any references to the object. When PHP decides to garbage collect (to free up some memory), it will destroy the UnlinkMe object, and thus call the __destruct method. Voila, we now call unlink and have cleaned up the file, even after the script has finished running.&lt;/p&gt;

&lt;p&gt;There is lots of room for improvement, and this technique has lots of gotchas. For example, PHP has some bizzare rules for when __destruct method will not be called. So please don&amp;#8217;t rely on this technique, but it might be useful, and keep your code cleaner and more organised.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>